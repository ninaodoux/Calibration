{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a23a95c9",
   "metadata": {},
   "source": [
    "# EXAMPLE LOOP THROUGH SCENARIO COMBINATIONS FOR ONE MODEL\n",
    "\n",
    "*using classes and calibration methods*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffe005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from CalibrationFunctions import DataPreprocessor, Calibrator, ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8d6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de676875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# INIT LISTS & CONSTANTS\n",
    "# ===========================================\n",
    "results = []\n",
    "dataset_sizes    = [10_000, 50_000, 380_000]\n",
    "imbalance_ratios = [0.004, 0.05, 0.2]\n",
    "calibration_methods = [\n",
    "    'isotonic', 'sigmoid', 'exponential', 'polynomial',\n",
    "    'bbq', 'venn_abers', 'hist_binning'\n",
    "]\n",
    "\n",
    "# ===========================================\n",
    "# LOOP THROUGH SCENARIOS\n",
    "# ===========================================\n",
    "for size in dataset_sizes:\n",
    "    # Load + sample + split\n",
    "    bp = DataPreprocessor('INSERT')\n",
    "    bp.load_data('my_path')\n",
    "    bp.sample_dataset(sample_size=size)\n",
    "    bp.prepare_data(test_size=0.2, calib_size=0.25)\n",
    "\n",
    "    for ratio in imbalance_ratios:\n",
    "        # Balance training set to desired positive:negative ratio\n",
    "        train_df = pd.concat([bp.X_train, bp.y_train], axis=1)\n",
    "        bp_balance = DataPreprocessor('INSERT')\n",
    "        bp_balance.train_df = train_df.copy()\n",
    "        bp_balance.X_train = train_df.drop('INSERT', axis=1)\n",
    "        bp_balance.y_train = train_df['INSERT']\n",
    "        bp_balance.balance_target_variable(method='ratio', target_ratio=ratio)\n",
    "        X_train_bal, y_train_bal = bp_balance.X_train, bp_balance.y_train\n",
    "\n",
    "        for use_weight in (False, True):\n",
    "            \n",
    "# ======================================================\n",
    "# compute dynamic class weight for additional comparison (unweighted VS weighted)\n",
    "# =======================================================\n",
    "            if use_weight:\n",
    "                spw = (y_train_bal == 0).sum() / (y_train_bal == 1).sum()\n",
    "                class_weight = {0: 1, 1: spw}\n",
    "            else:\n",
    "                class_weight = None\n",
    "\n",
    "            # initialize ONE model (example)\n",
    "            model = RandomForestClassifier(\n",
    "                n_estimators   = 500,\n",
    "                max_depth      = 6,\n",
    "                class_weight   = class_weight,\n",
    "                random_state   = 243,\n",
    "                n_jobs         = -1,\n",
    "                oob_score      = False\n",
    "            )\n",
    "            model.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "            # calibration evaluation\n",
    "            calib = Calibrator(\n",
    "                model     = model,\n",
    "                calib_set = (bp.X_calib, bp.y_calib),\n",
    "                test_set  = (bp.X_test, bp.y_test)\n",
    "            )\n",
    "            calib.evaluate('uncalibrated')\n",
    "            u_ece     = calib.metrics['uncalibrated']['ece']\n",
    "            u_logloss = calib.metrics['uncalibrated']['log_loss']\n",
    "\n",
    "            # apply calibration methods\n",
    "            for m in calibration_methods:\n",
    "                try:\n",
    "                    if m in ('isotonic', 'sigmoid'):\n",
    "                        calib.fit_calibrator(m, cv=5)\n",
    "                    elif m == 'hist_binning':\n",
    "                        calib.fit_calibrator(m, n_bins=15)\n",
    "                    elif m == 'bbq':\n",
    "                        calib.fit_calibrator(m, n_bins=15, prior=0.5, max_samples=300_000)\n",
    "                    elif m == 'exponential':\n",
    "                        calib.fit_calibrator(m)\n",
    "                    elif m == 'polynomial':\n",
    "                        calib.fit_calibrator(m, degree=3)\n",
    "                    elif m == 'venn_abers':\n",
    "                        calib.fit_calibrator(m, cal_size=0.2, random_state=101)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown calibration method `{m}`\")\n",
    "                    calib.evaluate(m)\n",
    "                except Exception:\n",
    "                    logging.warning(\n",
    "                        f\"Calibration {m} failed at size={size}, ratio={ratio}, weight={use_weight}\"\n",
    "                    )\n",
    "\n",
    "            # select best calibration by weighted score\n",
    "            best_score, best_method = float('inf'), None\n",
    "            for method, mets in calib.metrics.items():\n",
    "                if method == 'uncalibrated':\n",
    "                    continue\n",
    "                score = 0.7 * mets['ece'] + 0.3 * mets['log_loss']\n",
    "                if score < best_score:\n",
    "                    best_score, best_method = score, method\n",
    "\n",
    "            # compute pre- and post-calibration best scores\n",
    "            pre_score  = 0.7 * u_ece + 0.3 * u_logloss\n",
    "            post_score = best_score if best_method is not None else pre_score\n",
    "            pct_red    = 0.0 if pre_score == 0 else 100 * (pre_score - post_score) / pre_score\n",
    "\n",
    "            # record results\n",
    "            results.append({\n",
    "                'MODEL'           : 'RANDOM_FOREST',\n",
    "                'SIZE'            : size,\n",
    "                'RATIO'           : ratio,\n",
    "                'MIN-COUNT'       : int((y_train_bal == 1).sum()),\n",
    "                'WEIGHT'          : use_weight,\n",
    "                'PRE-ECE'         : u_ece,\n",
    "                'PRE-logloss'     : u_logloss,\n",
    "                'PRE-BEST-SCORE'  : pre_score,\n",
    "                'BEST-CAL'        : best_method or 'none',\n",
    "                'POST-ECE'        : calib.metrics.get(best_method, {}).get('ece', u_ece),\n",
    "                'POST-logloss'    : calib.metrics.get(best_method, {}).get('log_loss', u_logloss),\n",
    "                'BEST-SCORE'      : post_score,\n",
    "                'VARIATION'       : pct_red\n",
    "            })\n",
    "\n",
    "# save results to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('rf_bench.csv', index=False)\n",
    "logging.info(\"RF benchmark complete, results saved to rf_bench.csv\")\n",
    "\n",
    "\n",
    "# We can think of displaying the best method selected in the table \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
